\documentclass[parskip=half]{scrartcl}

\title{VeriDum: Computing SL+ and ISL+ Postconditions via Symbolic Execution}
\subtitle{LIS project report}
\date{2025-06-xx}
\author{ % random order
  Massimiliano Baglioni      \and
  Salvatore Salerno          \and
  Anna Francesca Montagnoli  \and
  Sofia Pisani               \and
  Lorenzo Pace               \and
  Jhonatan Azevedo Gonçalves \and
  Alessio Duè                \and
  Pamela Di Clemente         \and
  Emanuele Buonaccorsi}

\input{preamble.tex}

\begin{document}

\maketitle

\begin{abstract}
  We present VeriDum, a tool that computes SL+ and ISL+ postconditions for a simple nondeterministic imperative calculus. We start by introducing the target logics, then we outline VeriDum's implementation and demonstrate its operation with some examples.
\end{abstract}

\section{Introduction and Semantics Background}

One of the fundamental questions in software analysis is: \emph{is the program doing what we expect it to do?} More precisely: \emph{does the program behave as intended? Can we detect bugs, or even better, prove their absence? How can we reason about all the possible behaviors of the program?}
\\ These questions are not just about writing code — they are about understanding the \emph{meaning} of code. In other words, verifying that a program does what it is supposed to do amounts to checking whether it satisfies some \emph{semantic property} of interest.
\\ To reason about program correctness, we need to formally define what it means for a program to execute — that is, we need a semantics of the programming language. For example, we may ask:
\begin{itemize}
    \item What does it mean to execute a command \( c \)?
    \item How does its execution affect the program state \( \sigma \)?
\end{itemize}

\subsection{Denotational and Collective Semantics}
Given a program \( c \), we start from an initial state \( \sigma \) and aim to describe the resulting output state(s). This is captured by the denotational semantics:
\[
\llbracket c \rrbracket : \Sigma \rightarrow \Sigma_{\bot}, \quad \text{where } \Sigma_{\bot} = \Sigma \cup \{ \bot \}
\]
Here, \( \bot \) represents non-termination. So, for a given input state \( \sigma \), we interpret the command \( c \) as:
\[
\llbracket c \rrbracket \sigma = \sigma' \quad \text{or} \quad \bot
\]
To analyze instead \emph{all} possible behaviors of a program on a set of input states, we use \textbf{collecting semantics}:
\[
\llbracket c \rrbracket : \mathcal{P}(\Sigma) \rightarrow \mathcal{P}(\Sigma)
\]
This version of semantics operates on sets of states, and captures all potential outputs from all initial inputs:
\[
\llbracket c \rrbracket P = \bigcup_{\sigma \in P} \llbracket c \rrbracket \sigma
\]

As an example, consider the following simple program:
\[
c \triangleq \texttt{if (x > 0) \{ x := 1; \} else \{ x := 2; \}}
\]
\begin{itemize}
    \item Denotational Semantics. Given input state \( \sigma = \{ x \mapsto 0 \} \), we obtain: \( \llbracket c \rrbracket \sigma = \{ x \mapsto 2 \} \)
    \item Collecting Semantics. For a set of input states \( P = \{ x \mapsto -1, x \mapsto 0, x \mapsto 1 \} \), yields:
    $\llbracket c \rrbracket P = \{ x \mapsto 1, x \mapsto 2 \}$    
\end{itemize}

\subsection{Undecidability and Rice's Theorem}
Before stating Rice's theorem, we recall what is meant by a \emph{non-trivial semantic property}. A semantic property $\mathcal{P}$ of programs in a language $L$ is said to be \emph{non-trivial} if:

\begin{itemize}
  \item there exists at least one program $c \in L$ such that $\mathcal{P}(c)$ holds (i.e., $c$ satisfies the property), and
  \item there exists at least one program $c \in L$ such that $\mathcal{P}(c)$ does not hold (i.e., $c$ does not satisfy the property).
\end{itemize}

Unfortunately, checking whether a program satisfies such a property is undecidable in general. This follows from \textbf{Rice’s theorem}, which states that:

\begin{quote}
\emph{Let \( L \) be a Turing-complete language, and let \( \mathcal{P} \) be a non-trivial semantic property. Then there is no algorithm that can decide, for every program \( c \in L \), whether \( \mathcal{P}(c) \) holds.}
\end{quote}

Thus, there is no general analysis method that is \emph{automatic}, \emph{universal}, and \emph{exact}.
For some programs \( \mathcal{P}(c) \) holds, for others it does not, and in some cases — as in Collatz’s Conjecture — it is not even known whether the program terminates.
\\ Since we cannot achieve all three goals, we must compromise — giving up on automation, using instead interactive or semi-automated methods; giving up on universality, by analyzing only specific classes of programs; or relaxing on exactness, using approximations.
\\ The solution we provide gives up on exactness and introduces Over- and Under- approximations.
\textbf{Over approximation} ($\llbracket c \rrbracket P \subseteq Q$) is suitable for proving correctness: true negatives are preserved, but may introduce false positives.
Instead, \textbf{Under approximation} ($\llbracket c \rrbracket P \supseteq Q$) is suitable for bug-finding: true positives are preserved but may miss real behaviors (false negatives).

\subsection{Soundness and Completeness}

Ideally, we want:
\[
analysis(c) = \text{true} \iff \mathcal{P}(c) \text{ holds}
\]
This breaks down into:
\begin{itemize}
    \item \textbf{Soundness} ($analysis(c) = \text{true} \Rightarrow c \text{ satisfies the property } \mathcal{P}$): if the analysis says true, the property really holds.
    \item \textbf{Completeness} ($analysis(c) = \text{true} \Leftarrow c \text{ satisfies the property } \mathcal{P}$): if the property holds, the analysis says true.
\end{itemize}

Moreover, things can get easily complicated if we add \textbf{nondeterminism}, in which a command \( c \) maps a state to a set of possible output states (meaning that either do not terminate or terminate in Q):
\[
\llbracket c \rrbracket : \Sigma \rightarrow \mathcal{P}(\Sigma)
\]
This may be due to incomplete knowledge, abstract interpretation, or nondeterministic language constructs like \( c_1 \; \vert\vert \; c_2 \).
Showing (Non-)Termination isn't a trivial task. 
\begin{itemize}
    \item Using \textbf{over-approximation}, we can attempt to show \( \llbracket c \rrbracket \sigma \subseteq \emptyset \)
    \item Using \textbf{under-approximation}, we can try to find some \( Q \ne \emptyset \) such that \( Q \subseteq \llbracket c \rrbracket \sigma \)
\end{itemize}

In the next section, we introduce the logics standing at the basis of VeriDum. These are needed in order to formally proof correctness of programs relaxing, as we said before, the notion of exactness. 

\subsection{Hoare Logic}
We consider a simple imperative language $\mathcal{I}$ with the following syntax:

\textbf{Commands:} $\quad c ::= x := a \mid \texttt{skip} \mid c_1;\,c_2 \mid \texttt{if } b \texttt{ then } c_1 \texttt{ else } c_2 \mid \texttt{while } b \texttt{ do } c$

\textbf{Arithmetic Expressions:} $\quad a ::= n \mid x \mid a_1 + a_2 \mid a_1 - a_2 \mid a_1 * a_2 \mid a_1 / a_2$

\textbf{Boolean Expressions:} $\quad b ::= a_1 \leq a_2 \mid a_1 = a_2 \mid \neg b \mid b_1 \wedge b_2 \mid b_1 \vee b_2$


Given the following \textbf{Assertion Language} for writing preconditions and postconditions:
\begin{align*}
P &::= \texttt{true} \mid \texttt{false} \mid a_1 < a_2 \mid a_1 = a_2 \mid \neg P \mid P_1 \wedge P_2 \mid \exists x . P
\end{align*}

Given the following \textbf{Semantic Domains} defined as the set of mathematical objects used to interpret programs, i.e. the values on which the meaning of commands, expressions and programs is formalised: 
\begin{itemize}
\item $\sigma : X \rightarrow \mathbb{Z}$ is a \emph{state}, mapping variables to integers;
\item $\Sigma \triangleq {\sigma : X \rightarrow \mathbb{Z}}$ is the set of all possible program states;
\item $\mathcal{P}(\Sigma) \triangleq {P \mid P \subseteq \Sigma}$ is the powerset of $\Sigma$, representing sets of states.
\end{itemize}

Lastly, we recall that an \emph{inference rule} is a formal logical rule that allows deriving a conclusion from one or more premises. It is usually written in the form:
\[
\frac{\varphi_1 \quad \varphi_2 \quad \cdots \quad \varphi_n}{\psi}
\]
which means that if the premises $\varphi_1, \varphi_2, \ldots, \varphi_n$ hold, then the conclusion $\psi$ can be inferred.
A \emph{proof system} (or deductive system) is a set of inference rules and axioms that define how to derive valid formulas or judgments within a formal language. It provides a structured way to construct \emph{formal proofs}, i.e., finite sequences of applications of inference rules starting from axioms and leading to the desired conclusion.
In the context of program verification, a proof system allows us to derive correctness properties (e.g., Hoare triples) by applying inference rules that correspond to the programming constructs and logical assertions.
These rules are used to derive valid Hoare triples.
\\ A \emph{Hoare triple} \{ P \} c \{ Q \} expresses a partial correctness specification:
\begin{quote}
\emph{If the command $c$ is executed in a state where the precondition $P$ holds, and if the execution terminates, then the postcondition $Q$ will hold afterward.}
\end{quote}
Semantically, this means:
\begin{align*}
[[c]]P \subseteq Q
\end{align*}

This specification may include non-reachable states. This is called \textbf{partial correctness}, as it does not guarantee that the program terminates — only that if it does, the postcondition holds.
As it is deductible, Hoare triples rely on \emph{over-approximation} of program behaviors. This means that the set $[[c]]P$ includes all possible outcomes starting from states satisfying $P$, possibly including states that are not actually reachable, ensuring \emph{no false negatives} in verifying correctness.
\\ Verifying the correctness of \{ P \} c \{ Q \} corresponds to checking whether command $c$ satisfies the given specification. To construct formal proofs of partial correctness, we use axioms and inference rules. These constitute the axiomatic semantics of the language:

\textbf{(skip)} 
\[
\{P\} \;\texttt{skip}\; \{P\}
\]

\textbf{(assign)} 
\[
\{Q[a/x]\} \; x := a \; \{Q\}
\]

\textbf{(seq)} 
\[
\frac{\{P\} \; c_1 \; \{R\} \quad \{R\} \; c_2 \; \{Q\}}{\{P\} \; c_1; c_2 \; \{Q\}}
\]

\textbf{(cons)} 
\[
\frac{P \implies P' \quad \{P'\} \; c \; \{Q'\} \quad Q' \implies Q}{\{P\} \; c \; \{Q\}}
\]

\textbf{(cond)} 
\[
\frac{\{P \wedge b\} \; c_1 \; \{Q\} \quad \{P \wedge \neg b\} \; c_2 \; \{Q\}}{\{P\} \; \texttt{if } b \texttt{ then } c_1 \texttt{ else } c_2 \; \{Q\}}
\]

\textbf{(while)} 
\[
\frac{\{P \wedge b\} \; c \; \{P\}}{\{P\} \; \texttt{while } b \texttt{ do } c \; \{P \wedge \neg b\}}
\]
\\ We say:
\begin{itemize}
\item A triple \{ P \} c \{ Q \} is \textbf{semantically valid} if $[[c]]P \subseteq Q$;
\item It is \textbf{provable} if there exists a derivation tree with that triple as root;
\item The proof system is \textbf{sound}: only valid triples are provable;
\item Under certain conditions (e.g., availability of weakest preconditions), the system is also \textbf{complete}.
\end{itemize}

Multiple preconditions or postconditions may be valid for a given Hoare triple. Prefer the \emph{weakest precondition} (i.e., the most general one), and the \emph{strongest postcondition} (i.e., the most precise one), because a weakest precondition guarantees correctness for the largest possible set of initial states, making the specification more broadly applicable. A strongest postcondition ensures the most informative and constrained outcome, capturing the exact behavior of the program.
\\It is possible to weaken preconditions thanks to \textbf{Weakest Liberal Preconditions (Dijkstra)}; given a command $c$ and a postcondition $Q$, the \emph{weakest liberal precondition} $\text{wlp}(c, Q)$ is the least restrictive condition such that:
\begin{align*}
\forall R. \quad {R}, c, {Q} \text{ iff } R \Rightarrow \text{wlp}(c, Q)
\end{align*}
Formally:
\begin{align*}
\text{wlp}(c, Q) = {\sigma \in \Sigma \mid [[c]]{\sigma} \subseteq Q}
\end{align*}

Hoare Logic can be extended to handle \textbf{nondeterministic computations} by introducing a richer syntax of \emph{regular commands}. These commands allow us to represent nondeterministic behavior through constructs such as choice, assumption, and iteration.
\\ The language of regular commands $r$ includes both atomic and compound constructs:

\begin{align*}
  c &::= \texttt{skip} \mid x := a \mid b? && \text{(atomic commands)} \\
  r &::= c \mid r_1 ; r_2 \mid r_1 + r_2 \mid r^* && \text{(compound commands)}
\end{align*}

\noindent
The \emph{assumption} command $b?$ represents a conditional guard that blocks execution unless the Boolean expression $b$ holds. The \emph{nondeterministic choice} $r_1 + r_2$ allows either branch to be taken arbitrarily, and the \emph{iteration} operator $r^*$ denotes zero or more repetitions of $r$, following the Kleene star law:
\[
r^* \equiv \texttt{skip} + r ; r^*
\]

The extension of Hoare Logic with nondeterminism allows reasoning about programs that do not have a single predictable behavior. This is essential in modeling systems with inputs, concurrency, or abstract scheduling. The semantics and proof rules are designed to be conservative: for instance, in the choice rule, both branches must independently ensure the same postcondition to guarantee correctness under all possible execution paths. The iteration rule captures loops via invariant reasoning, in a style reminiscent of fixed-point definitions.



\subsection{Incorrectness Logic}

Incorrectness Logic (IL) is a logic that complements Hoare Logic by focusing on the detection of program errors and the certification of incorrectness. While Hoare Logic is used to prove that programs behave correctly, Incorrectness Logic aims to prove that they behave \emph{incorrectly}—or more precisely, that certain erroneous states are \emph{reachable}.

Aa seen, a standard Hoare triple is written as: $\{P\}~c~\{Q\}$ and expresses that if command $c$ is executed in a state satisfying $P$, and if it terminates, then the resulting state will satisfy $Q$. This implies the semantic condition: $\llbracket c \rrbracket P \subseteq Q$
i.e., all reachable states are contained in $Q$.

In contrast, an Incorrectness Logic triple is written as:
\[
[P]~c~[Q]
\]
and asserts that: \emph{any state in $Q$ is guaranteed to be reachable by executing $c$ from some state in $P$}. Semantically:
\[
\llbracket c \rrbracket P \supseteq Q
\]
i.e., the postcondition $Q$ \emph{under-approximates} the set of reachable states. This distinction makes IL particularly useful for bug-finding and validation of counterexamples.
\\Incorrectness Logic is based on \textbf{}{under-approximation}: it guarantees that all the post-states in $Q$ are reachable from some state in $P$, but it does not require completeness over all executions. This is complementary to Hoare Logic, which relies on \emph{over-approximation}.
\\ Incorrectness Logic and Hoare Logic can be used together under the following principles:

\begin{itemize}
  \item \textbf{Principle of Agreement}: If an IL triple $[P']~c~[Q']$ is valid, and $P' \Rightarrow P$, and the HL triple $\{P\}~c~\{Q\}$ is valid, then $Q' \Rightarrow Q$. This shows that IL and HL can reinforce each other—any postcondition found via IL must be consistent with correctness guarantees from HL.
  \item \textbf{Principle of Denial}: If $[P']~c~[Q']$ is valid, $P' \Rightarrow P$ and $Q' \not\Rightarrow Q$, then the HL triple $\{P\}~c~\{Q\}$ is not valid. This provides a counterexample to correctness.
\end{itemize}
We say that an Incorrectness Logic triple $[P]~c~[Q]$ is:

\begin{itemize}
  \item \textbf{Valid} if $\llbracket c \rrbracket P \supseteq Q$; that is, every state in $Q$ is reachable from $P$.
  \item \textbf{Sound} if every provable triple is valid. IL is sound.
  \item \textbf{Complete} if every valid triple is provable. IL is complete relative to the assertion language and semantic model.
\end{itemize}
IL uses the same language and semantic domains as Hoare Logic. The assertion language includes Boolean expressions and quantifiers. 
\paragraph{Reasoning Style.}
Incorrectness Logic is especially suited for proving that specific erroneous outcomes are possible. It is scalable, modular, and particularly helpful for:
\begin{itemize}
  \item reasoning about partial program executions,
  \item counterexample generation,
  \item supporting debugging and bug detection.
\end{itemize}

IL lets us deliberately \emph{drop execution paths} (e.g., in nondeterministic branches or loop iterations) so long as we retain at least one valid path to the postcondition. This contrasts with Hoare Logic, where we must account for all execution paths.

\subsection{Separation Logic} \label{SL}

Separation Logic (SL) is a logic for reasoning about programs that manipulate pointers and dynamic memory allocation. 
It extends Hoare Logic with a new operator, the separating conjunction \(\ast\), which allows reasoning about disjoint parts of the heap.

\ie \(P_1 \ast P_2\)
means that we have two disjoint subheaps, one satisfying \(P_1\) and the other satisfying \(P_2\).

The local axioms of SL are the following:

\textbf{(read)} 
\[
\frac{}{\{y\mapsto v\}\ x:=[y]\ \{x=v\wedge y\mapsto v\}}
\]

\textbf{(write)} 
\[
\frac{}{\{x\mapsto \_\}\ [x]:=y\ \{x\mapsto y\}}
\]

\textbf{(allocation)} 
\[
\frac{}{\{emp\}\ x:=alloc()\ \{x\mapsto \_\}}
\]

\textbf{(deallocation)} 
\[
\frac{}{\{x\mapsto \_\}\ free(x)\ \{emp\}}
\]

These axioms are called local because they only specify preconditions and postconditions for the used part of the memory. All others can be added via the Frame rule, which is the core of SL. The Frame rule allows us to extend a local proof to a larger context by embedding the proof of a small part of a program within a bigger heap, as long as the additional parts of the heap remain unaffected.

\textbf{(Frame rule)} 
\begin{align*}
    \frac{\{P\}\ r\ \{Q\}}{\{P\ast R\}\ r\ \{Q\ast R\}}mod(r)\cap fv(R)=\emptyset
\end{align*}
A program that executes safely in a small state (satisfying \(P\)), can also execute in any bigger state (satisfying \(P\ast R\)) and its execution will not affect the additional part of the state (and so \(R\) will remain true in the postcondition).
The side condition of the rule states that the command \(r\) should not modify the free variables in \(R\).

\paragraph{Incompleteness}
One known limitation of SL is its incompleteness: there exists valid SL triples that are not provable.

In fact we cannot find a derivation for the following triple:
\[
\{y\mapsto\_\ast x\mapsto\_\}(false?;x:=[y])+(true?;skip)\{y\mapsto\_\ast x\mapsto\_\}
\]

We can't apply the Frame rule since $x\in mod(r)$, but the branch modifying $x$ is actually not reachable.

\subsection{Incorrectness Separation Logic} \label{ISL}
Incorrectness Separation Logic (ISL) is a formal system designed to reason about the potential incorrect behaviors of programs, particularly those that manipulate memory. It combines principles from both Incorrectness Logic (IL), which focuses on under-approximate reasoning about program errors, and Separation Logic (SL), which provides tools to reason locally about memory and heap-manipulating code.

Just as in Separation Logic, Incorrectness Separation Logic includes a frame rule that enables reasoning about programs operating on disjoint memory regions. The frame rule in ISL is stated as follows:
\begin{align*}
    \frac{[P]\ r\ [\epsilon: Q]}{[P\ast R]\ r\ [\epsilon: Q\ast R]}mod(r)\cap fv(R)=\emptyset
\end{align*}

The core of ISL consists of local axioms that specify the behavior of simple commands. These axioms reflect both successful execution (\texttt{ok}) and erroneous behavior (\texttt{er}).
\\\\
\textbf{(write)} 
\[
\frac{}{[x\mapsto v]\ [x]:=y\ [ok:x\mapsto y]}
\]

\[
\frac{}{[x=nil]\ [x]:=y\ [er:x=nil]}
\]

\textbf{(read)} 
\[
\frac{}{[y\mapsto v]\ x:=[y]\ [ok:x=v\wedge y\mapsto v]}
\]

\[
\frac{}{[y=nil]\ x:=[y]\ [er:y=nil]}
\]

\textbf{(allocation)} 
\[
\frac{}{[x\doteq x']\ x:=alloc()\ [ok:x\mapsto \_]}
\]
The precondition indicates that $x'$ is the old value of $x$ before the assignment.
\\\\
\textbf{(deallocation)} 
\[
\frac{}{[x\mapsto v]\ free(x)\ [ok:x\not\mapsto]}
\]
The postcondition uses $x\not\mapsto$ to track the deallocated locations, this way resources cannot shrink, preserving the soundness of the Frame rule.

\[
\frac{}{[x=nil]\ free(x)\ [er:x=nil]}
\]
\\\\
\paragraph{Incompleteness}
Incorrectness Separation Logic, like Separation Logic, also suffers from incompleteness: there exists valid ISL triples that are not provable.

For example if we take the following valid ISL triple
\[
[y\mapsto v]\ x:=alloc();free(y);x:=[y]\ [y\not\mapsto\ast x\mapsto\_]
\]
we cannot find a derivation.

\subsection{Dummy variables}
One of the principles of SL and ISL is the locality. This means that the logic is capable of analyzing code sections regardless of the general state of the whole program. If we look into the incompleteness example of Section \ref{SL} we could argue that it represents a failure of the locality principle, since the rule is invalid due to some commands that will never be executed. But notice that if we somehow had a better way to keep track set of which variables were edited, the rule would be valid. Seeking this more precise set of modified variables, dummy variables were proposed.

Unlike program variables, which are directly manipulated by program commands, dummy variables are introduced only in the assertion language. Their core property is immutability, and once instantiated, their values remain fixed. This stability allows them to express conditions related to the initial or expected values of the program variables. So, a new shorthand assertion \(emp_X\) analogous to the classical \(\mathsf{emp}\) predicate was introduced. However, instead of asserting an empty heap, \(emp_X\) imposes that aside from the heap being empty, there also exists a corresponding dummy variable \(x'\) for each program variable \(x \in X\).

\[
emp_X \triangleq \bigwedge_{x \in X} \exists x'.\ x = x'
\]

Dummy variables are particularly useful in the context of framing. When dealing with separation logic, we noticed that we may need to frame over memory fragments that refer only to unmodifiable entities (e.g., disallowing references to variables that might be modified). By referring only to dummy variables, frames can provide constraints over unaccessible states, which is essential for preserving locality in the presence of heap-manipulating commands. Moreover, their presence in either preconditions or postconditions, but not both, guarantees that the program variable was not modified over the execution.

Using the new \(emp_X\) assertion in the incompleteness example of Section \ref{SL}, we may now derive the tuple that was not possible to be derived in Separation Logic.


\[
\inferrule*[Right=\textsc{Frame}]
      {%
        \inferrule*[Right=\textsc{Choice}]
          {%
            % ----- left branch:  false? ; x := [y] -----------------
            \inferrule*
              {\,}
              {\triple{\empX}{\textbf{false?}\;;\;x := [y]}{\bot}}
            \quad
            % ----- right branch:  true? ; skip ---------------------
            \inferrule*
              {\,}
              {\triple{\empX}{\textbf{true?}\;;\;\textbf{skip}}{\empX}}
          }
          {\triple{\empX}{\cmd}{\empX}}
      }
      {\triple{\empX * y\mapsto{\_} * x\mapsto{\_}}{\cmd}{\empX * y\mapsto{\_} * x\mapsto{\_}}}
\]


\subsection{SL+ and ISL+}

The ``+'' variants, SL+ and ISL+, are extensions of their classical counterpart systems. The main difference between SL, ISL and their plus versions is the usage of dummy variables to keep track of modified variables. Instead of requiring that frame assertions do not mention variables modified by the program, SL+ and ISL+ allow framed assertions to only mention dummy variables. This condition permits more powerful and complete derivations by ensuring that only variables that were changed are excluded from frames.

Because SL and ISL differ in approximation style, the effect of these changes differs accordingly. SL+ improves partial-correctness reasoning by enabling stronger postconditions. ISL+, on the other hand, improve bug-finding capabilities. Under-approximate rules like allocation, load, and free can now be used even when framing memory that overlaps with modified state, as long as that memory is referred to only through dummy variables. This removes some restrictions that previously blocked a few proofs.

In summary, SL+ and ISL+ retain the core reasoning of their classical counterparts, over- and under-approximate separation logic, while expanding expressiveness. By introducing dummy variables and a semantics-driven frame rule, the ``+'' variants enable richer assertions, better locality, and overall a more complete and modular proof systems for both correctness and incorrectness reasoning in heap-manipulating programs.




\section{Symbolic execution}

We will now describe the main components of VeriDum, starting from the executor. The code discussed here is available at \url{https://github.com/dalz/lis-project/}.

Given a precondition and a program, we produce a postcondition by means of symbolic execution. The program is executed step by step, using the postcondition of each command as the precondition of the next.

\subsection{Executor state}

During symbolic execution, the logical proposition that is currently known to hold (\ie the postcondition of the previous command or initial precondition) is kept in a normal form with the following shape:
\begin{align*}
  &x = x' \wedge y = y' \wedge \dots \\
  &\wedge (x' \mapsto a_1 \ast x'' \mapsto a_2 \ast \dots \ast y' \mapsto b_1 \ast y'' \mapsto b_2 \ast \dots) \\
  &\wedge p
\end{align*}
\ie a single equality between each program variable and a dummy variable, the heap with possibly a chunk for each dummy variable (but not for program variables), and a path condition \(p\). The path condition is a conjunction of comparisons and boolean constants, and cannot contain program variables.

In OCaml, this is implemented as the following type (from \texttt{executor\_state.ml}):
\begin{minted}{ocaml}
  type heapval =
    | Val of Aexp.t (* x ↦ e *)
    | Undefined     (* x ↦ _ *)
    | Dealloc       (* x ↦̸   *)

  type t = {
    dummies : (Ide.t, Dummy.t, Ide.comparator_witness) Map.t;
    heap : (Dummy.t, heapval, Dummy.comparator_witness) Map.t;
    path_cond : Path_cond.t;
  }
\end{minted}

The motivation for keeping equalities on program variables (\ml{Ide.t}) separate from the rest is to be always able to apply the frame rule without extra processing. Propositions can be framed out only if they don't include program variables, so the only piece of the normal form that cannot be framed out is the \ml{dummies} map. All rules take either a generic proposition or a proposition that includes \(\mathrm{emp}_{\mathbb X_{p}}\), that can always match the formula represented by \ml{dummies}, which consequently never needs to be framed out.

The heap is represented by a map to easily identify duplicate chunks, that imply falsehood.

The path condition cannot contain disjunctions, as the executor state represents a single branch in the symbolic execution. Whenever a disjunction would be produced, the executor is called on the two branches with two separate states instead. Moreover it doesn't need existential quantifiers as they are removed by the normalization procedure.

\subsection{Normalization}

We produce a list of executor states from the input precondition as follows.
First, we rewrite the precondition to an intermediate form with the shape
\[\exists X.\;\bigvee_{i}\bigast_{j}\bigwedge_{k} A_{ijk},\]
with \(A\) an atomic proposition, by distributivity rules and pushing out of existential quantifiers (\texttt{norm\_prop.ml}). Then we separate the disjunct; we will produce a distinct state for each of them. We replace all program variables with fresh dummy variables, and remember the association in the \ml{dummies} map. Finally, we extract the chunks into the \ml{heap} map and put the rest into the path condition, turning \(\ast\) into \(\wedge\) as they are equivalent in the absence of chunks.

If we find two chunks for the same location in the same separating conjunct (\ie connected by \(\wedge\)), we keep only one in the \ml{heap} map and add an equality between the pointed-to values to the path condition. If we find them in the same disjunct (connected by \(\ast\)) we add false to the path condition.

Once they are at the outermost level, existential quantifiers can be eliminated according to the Exists rule.

\subsection{Executor status}

Executor states are wrapped in a monad that tracks the current status of the executor: produced a value, encountered an error, unable to apply any rule.

\begin{minted}{ocaml}
  type 'a status =
    | Ok of 'a (* typically 'a = Executor_state.t *)
    | Err of Executor_state.t
    | Stuck of Executor_state.t
\end{minted}

The executor is parameterized over the bind operator of the status monad, to generalize over SL+ and ISL+'s differing interpretations of errors.

\begin{minted}{ocaml}
  (* SL+ *)
  let bind x f =
    match x with Ok s -> f s | Err s -> [ Stuck s ] | Stuck _ -> [ x ]

  (* ISL+ *)
  let bind x f =
    match x with
    | Ok s -> f s
    | Err s ->
        List.map (f s) ~f:(function Ok z -> Err z | (Err _ | Stuck _) as z -> z)
    | Stuck _ -> [ x ]
\end{minted}

When composing two computations \(f\) and \(g\), if the \(f\) an \ml{Ok} result then \(g\) is always executed; if \(f\) gets stuck the state is returned immediately, without executing \(g\); errors are turned into stuck states in SL+, while in ISL+ execution continues but \ml{Ok} results of \(g\) are turned into errors.

\subsection{Executor}

The executor is parameterized by a configuration record, which includes the bind operator and functions implementing the rules that differ between SL+ and ISL+. It takes as input an executor state and a program, and returns a list of statuses, the possible outcomes (postconditions) of executing the program.

At the end of the execution of the whole program we join the postconditions with disjunctions (according to the Disj and Choice rules) in SL+, while we keep them as different possible outcomes (derivable postconditions) in ISL+.

\begin{minted}{ocaml}
  let rec exec cfg s p : Executor_state.t status list =
    let ( let* ) (ss : Executor_state.t status list) f =
      List.concat_map ss ~f:(fun s -> cfg.bind s f)
    in
    let open Prog in
    if Path_cond.is_false s.path_cond then []
    else
      let* s =
        match p with
        | Cmd c -> exec_cmd ~alloc_rule:cfg.alloc_rule s c
        | Seq (p1, p2) ->
            let* s = exec cfg s p1 in
            cfg.on_step s;
            exec cfg s p2
        | Choice (p1, p2) ->
            cfg.choice_rule s p1 p2
            |> List.concat_map ~f:(fun (s, p) -> exec cfg s p)
        | Iter p -> cfg.iter_rule (exec cfg) ( let* ) s p
      in
      match Executor_state.simpl s with Some s -> [ Ok s ] | None -> []
\end{minted}

We will briefly go over the implementation of all the rules.

\subsubsection{Commands}

The \ml{exec_cmd} function handles the following cases:

\minisec{Skip}

Successfully returns the current state as is.

\begin{minted}{ocaml}
  | Skip -> [ Ok s ]
\end{minted}

\minisec{Assert}

Corresponds to the \texttt{?} operator in the syntax.

Adds the boolean expression to the path condition. If the expression contains disjunctions multiple states are returned, one for each choice.

\begin{minted}{ocaml}
  | Assert e ->
      List.map (Executor_state.add_bexp_to_path_cond s e) ~f:(fun s -> Ok s)
\end{minted}

\minisec{Assign}

Assignment of an arithmetic expression \texttt{e} to a program variable \texttt{x} is performed as follows:
\begin{enumerate}
\item Create a fresh dummy variable \texttt{x'}.
\item Replace all program variables in \texttt{e} with dummy variables, obtaining \texttt{e'}. A variable \texttt{y} is replaced with \texttt{y'} if \texttt{y = y'} is in the executor state (\ie \texttt{y} maps to \texttt{y'} in \ml{s.dummies}), or with a fresh dummy variable (which is then added to \ml{dummies}) otherwise.
\item \texttt{x = x'} is added to \texttt{dummies} (possibly replacing a previous association of \texttt{x} to a dummy variable) and \texttt{x' = e'} to the path condition.
\end{enumerate}

So for each change to a program variable we introduce a new dummy variable that reflects that change. This differs from the original rules of the logic in that there the dummy variables are created implicitly and as needed. We instead chose an eager approach to facilitate the automated application of the frame rule.

\begin{minted}{ocaml}
  let assign s x e =
    let x' = Dummy.fresh_of_ide x in
    let dummies, e' = Executor_state.dummify_aexp s.dummies e in
    let e' = Aexp.simpl e' in
    Executor_state.add_bexp_to_path_cond
      { s with dummies = Map.set dummies ~key:x ~data:x' }
      (Cmp (Eq, Var x', e'))
    |> List.hd_exn
\end{minted}

\minisec{Load}

Corresponds to the \texttt{x ← [y]} syntax.

Looks up the dummy variable \texttt{y'} associated to \texttt{y}, then looks for \texttt{y' = 0} in the path condition, returning an error if it finds it. Otherwise, it finds a chunk for \texttt{y'} in the heap and assigns it to \texttt{x} as discussed above. \ml{heap_val} returns an error if \texttt{y'} has been deallocated, and \texttt{Stuck} if it was never allocated or is undefined (allocated but never assigned).

Note that in SL+ \ml{Err} is turned into \ml{Stuck} by the status monad, so we can reuse the same implementation for both logics even if ISL+ continues execution after reading from a null or deallocated location (in an error state) and SL+ doesn't.

\begin{minted}{ocaml}
  | AssignFromRef (x, y) ->
      let* y' = dummy_of y in
      if Path_cond.is_null s.path_cond y' then [ Err s ]
      else
        let* e = heap_val y' in
        [ Ok (assign s x e) ]
\end{minted}

\minisec{Store}

Stores (\texttt{[x] ← y}) work similarly, returning an error if \texttt{x}'s dummy variable \texttt{x'} is null or deallocated, and getting stuck if it was never allocated.

\texttt{store s x' v} adds a \texttt{x' ↦ v} chunk to the heap.

\begin{minted}{ocaml}
  | AssignToRef (x, y) ->
      let* x' = dummy_of x in
      if Path_cond.is_null s.path_cond x' then [ Err s ]
      else
        let v =
          match Map.find s.dummies y with
          | Some y' -> Aexp.Var y'
          | None -> Aexp.Num 0
        in
        let* _ = heap_has x' in
        [ Ok (store s x' (Val v)) ]
\end{minted}

\minisec{Allocation}

In SL+, \texttt{x ← alloc()} creates a new dummy variable \texttt{x'}, sets it as the current dummy variable for \texttt{x}, and adds a \texttt{x ↦ \_} chunk to the heap.

\begin{minted}{ocaml}
  let alloc_rule s x =
    let x' = Dummy.fresh_of_ide x in
    Ok
      Executor_state.
        {
          s with
          heap = Map.set s.heap ~key:x' ~data:Undefined;
          dummies = Map.set s.dummies ~key:x ~data:x';
        }
\end{minted}

In ISL+, we can additionally reuse previously deallocated locations. Interactively we ask the user whether to do it (and which to reuse) or not. Non-interactively we always reuse the first deallocated location we find. Sample implementation without the interactive choice:

\begin{minted}{ocaml}
  let alloc_rule s x =
    let open Executor_state in
    let x' =
      Map.to_alist s.heap
      |> List.find_map ~f:(function x', Dealloc -> Some x' | _ -> None)
      |> Option.value_or_thunk ~default:(fun () -> Dummy.fresh_of_ide x)
    in
    Ok
      {
        s with
        heap = Map.set s.heap ~key:x' ~data:Undefined;
        dummies = Map.set s.dummies ~key:x ~data:x';
      }
\end{minted}

\minisec{Free}

Similar to store, but replaces a \texttt{x' ↦ \_} or \texttt{x' ↦ v} chunk with \texttt{x' ↦̸}.

\begin{minted}{ocaml}
  | Free x ->
      let* x' = dummy_of x in
      if Path_cond.is_null s.path_cond x' then [ Err s ]
      else
        let* _ = heap_has x' in
        [ Ok (store s x' Dealloc) ]
\end{minted}

\minisec{Error}

Unsurprisingly:

\begin{minted}{ocaml}
  | Error -> [ Err s ]
\end{minted}

\subsubsection{Sequence}

This is simply a matter of executing the two programs in sequence. The bind operator takes care of errors, stuck executions, and branching (the second \ml{exec} call is applied to \emph{all} postconditions generated by the first).

\begin{minted}{ocaml}
  | Seq (p1, p2) ->
    let* s = exec cfg s p1 in
    cfg.on_step s;
    exec cfg s p2
\end{minted}

\subsubsection{Choice}

This rule differs between SL+ and ISL+. In the former we execute both branches, in the latter we may select either both or a single one.

\begin{minted}{ocaml}
  | Choice (p1, p2) ->
    cfg.choice_rule s p1 p2
    |> List.concat_map ~f:(fun (s, p) -> exec cfg s p)
\end{minted}

The SL+ implementation:
\begin{minted}{ocaml}
  let choice_rule s p1 p2 = [ (s, p1); (s, p2) ]
\end{minted}

In ISL+ we let the user choose the branch(es) interactively, or pick one at random.

\subsubsection{Iteration}

Iteration again differs between the two logics.

In ISL+, we can simply choose a number of iterations to perform (unrolling):
\begin{minted}{ocaml}
  let iter_rule exec ( let* ) s p =
    let rec unroll s n =
      if n = 0 then [ Ok s ]
      else
        let* s = exec s p in
        unroll s (n - 1)
    in
    unroll s 7
\end{minted}

In SL+, we use AI\footnote{Abstract Interpretation} to identify a loop invariant:
\begin{minted}{ocaml}
  let iter_rule exec ( let* ) s p =
    let* s' = exec s p in
    let s'' = Executor_state.abstract_join s s' in
    let* s''' = exec s'' p in
    [ Ok (Executor_state.abstract_join ~ensure_equal:true s'' s''') ]
\end{minted}
we execute the loop body once, find a proposition that is valid both before and after the iteration (candidate invariant) via the \ml{abstract_join} function, then execute again the body using that proposition as the precondition. If the candidate is equivalent to the postcondition after the latter iteration we use it as the invariant. If it isn't, a trivial postcondition (true) is returned.

\ml{abstract_join} performs a simple abstract interpretation of the path condition over the domain of integer bounds. For example, it interprets \(x + 1\) as \(\geq 0\) if \(x = 0\). This is enough to conclude:
\begin{minted}{text}
  { 0 ≤ x ∗ 0 ≤ y }  (y ← y + x)⋆  { 0 ≤ y }
\end{minted}

We don't support invariants involving changes to the heap; if the heap is modified in the loop, we use true as the invariant.

Since we create a new dummy variable for each change to a program variable, loop bodies that modify a variable never have their precondition equal to the postcondition. For example:
\begin{minted}{text}
  { x = 0 }  x ← 0  { x = 0 }
\end{minted}
is actually:
\begin{minted}{text}
  { x = x' ∧ x' = 0 }  x ← 0  { x = x'' ∧ x' = 0 ∧ x'' = 0 }
\end{minted}
so when checking for equality we keep only the last version of each dummy variable and ignore the superscript. Here we would be comparing \texttt{\{ x = x' ∧ x' = 0 \}} with \texttt{\{ x = x'' ∧ x'' = 0 \}} and considering \texttt{x'} equal to \texttt{x''}.

\subsection{De-noising the postcondition}
After computing the postcondition in both SL+ and ISL+, an additional step can be applied to \textit{denoise} it from any unused dummy variable.

The approach works by maintaining a set $S$ of currently active dummy variables. For each atomic proposition in the postcondition's path condition:
\begin{enumerate}
\item If the atomic proposition contains no dummy variables at all, or contains at least one dummy variable that belongs to $S$, it is considered active and is kept. Any dummy variables present in this kept proposition are then added to $S$.
\item Otherwise, the atomic proposition is considered inactive and is pruned from the postcondition.
\end{enumerate}
The process is repeated until $S$ is no longer updated with a new element.
This logic is implemented in the \texttt{dummy\_dismantler} function of the executor state. The function is invoked during execution in both SL+ and ISL+ by default, and can be disabled via the \texttt{--keep-dummies} flag.

\section{Simplification}

At various points a number of simplification procedures are applied to the formulas generated by the executor. The key ones are those for executor states, path conditions and arithmetic expressions.

Arithmetic simplification (\texttt{aexp.ml}) applies a set of rewriting rules that push parentheses and constants to the right, replacing subexpressions with their computed result whenever possible.

Path conditions are conjunctions of boolean constants and comparisons. Simplification eliminates the constants and applies arithmetic simplification to the operands of the comparisons. It then tries to reason about bounds, \eg eliminating \texttt{x < 1} from \texttt{x < 0 ∧ x < 1}. % FIXME doesn't work

To simplify an executor state we first invoke the path condition simplification procedure, then try to extract and apply substitutions from the path condition. For example, if we have \texttt{x' = 0} in the path condition and \texttt{y' ↦ x'} in the heap, we replace the chunk with \texttt{y' ↦ 0}; from \texttt{x' ↦ \_ ∗ y' ↦ \_ ∧ x' = y'} we deduce false.

We also have a few more basic procedures for other types, such as the AST produced from reading the user's precondition and from the final list of executor states.

\section{Front-end}
Users can compile and run the project with the following commands:
\begin{verbatim}
  $ opam install . --deps-only
  $ dune build
  $ _build/default/bin/main.exe [--sl|--isl] [--step-exec] [--no-verbose] [--keep-dummies] <file>
\end{verbatim}

A valid input file must specify a precondition and a program, adhering to the following standard structure:

\begin{minted}{text}
{ precondition }
program
# Comments can be written by starting them with an '#'
\end{minted}

Files can have as extension either \texttt{.sl} or \texttt{.isl}, 
indicating whether they should be executed using 
\textit{Separation Logic+} or \textit{Incorrectness Separation Logic+}.

\subsection{Starting the execution}
The application's entry point is defined in \texttt{main.ml}.
Upon execution the application attemps to load the file and then passes it to the lexer, defined in \texttt{lexer.mll}. 
The file is scanned from beginning to end, stripping away any syntatic sugar and identifying valid tokens.
The more complex tokens are handled as follows:

\begin{enumerate}
  \item Any sequence of characters starting with a \# is considered a comment, thus ignored by the lexer.
  
  \item \texttt{INT:} a sequence of digits is recognized as an integer. 
  The string is then converted into an OCaml's integer value and wrapped in the \texttt{INT} token.
      

  \item \texttt{ID:} an identifier is recognized as a sequence of alphabetic characters (both uppercase and lowercase) which does not match any other token. 
        The matching text is stored as part of the \texttt{ID} token.
  
  \item \texttt{DUMMY\_ID}: a dummy identifier is similar to an identifier, with the exception that
        its sequence must end with one or more '\textbackslash{}'.
        The portion before the backslashes is treated as the name, while the number of backslashes corresponds to the number of apices of the variable.
        Both values are wrapped into the \texttt{DUMMY\_ID} token: the name as a string and the number of apices as an integer.
\end{enumerate}

The list of remaning valid tokens is the following:
\begin{multicols}{3} % Adjust number of columns as needed
\begin{itemize}
\item LPAREN = \texttt{(}
\item RPAREN = \texttt{)}
\item LBRACE = \texttt{\{}
\item RBRACE = \texttt{\}}
\item PLUS = \texttt{+}
\item MINUS = \texttt{-}
\item MULT = \texttt{**} | \texttt{×}
\item DIV = \texttt{/}
\item MOD = \texttt{\%}
\item BOOL(true) = \texttt{true} | \texttt{⊤}
\item BOOL(false) = \texttt{} | \texttt{⊥}
\item OR = \texttt{||} | \texttt{∨}
\item AND = \texttt{\&\&} | \texttt{∧}
\item NOT = \texttt{!} | \texttt{¬}
\item LT = \texttt{<}
\item LE = \texttt{<=} | \texttt{≤}
\item GT = \texttt{>}
\item GE = \texttt{>=} | \texttt{≥}
\item EQ = \texttt{=}
\item NEQ = \texttt{!=} | \texttt{<>} | \texttt{≠}
\item EMP = \texttt{emp}
\item REF = \texttt{->} | \texttt{↦}
\item NREF = \texttt{!->} | \texttt{!↦} | \texttt{↦̸}
\item SOMETHING = \texttt{\_}
\item EXIST = \texttt{exists} | $\exists$
\item SEP = \texttt{*} | \texttt{∗}
\item DOT = \texttt{.}
\item SEMICOLON = \texttt{;}
\item SKIP = \texttt{skip}
\item QUESTION = \texttt{?}
\item LBRACK = \texttt{[}
\item RBRACK = \texttt{]}
\item ASSIGN = \texttt{:=} | \texttt{←}
\item ALLOC = \texttt{alloc}
\item FREE = \texttt{free}
\item ERROR = \texttt{error}
\item STAR = \texttt{star} | \texttt{⋆}
\end{itemize}
\end{multicols}

The lexer then returns the ordered list of generated tokens, which is then passed to the parser, defined in \texttt{parser.mly}.
The parser's purpose is to check whether this sequence of tokens forms a syntactically correct program and if so, it trasforms it into an Abstract Syntax Tree(AST).
The principal parsed AST types are:

\begin{enumerate}
  \item \texttt{Aexp.t}: an arithmetic expression. It can be either a binary operator between two valid arithmetic expressions (addition, subtraction, multiplication, division or modulo), the negation of an arithmetic expression, or the equality between an arithmetic expression and a variable (an \texttt{ID} token).

  \item \texttt{Bexp.t}: a boolean expression. It can be either a boolean constant (true or false), a comparison between two valid arithmetic expressions, the conjunction or disjunction between two boolean expression, or the negation of a boolean expression.

  \item \texttt{Dummy.t}: an identifier. A \texttt{ID} token is treated as a dummy variable with number of apices equal to 0; a \texttt{DUMMY\_ID} token creates a dummy variable with the associated number of apices.
  
  \item \texttt{Atom.t}: an atomic proposition. It can be either a boolean expression, a points-to-anything assertion of the form $x \rightarrow \_$, a points-to assertion with an arithmetic expression in the form $x \rightarrow a$, a dangling pointer assertion in the form $x \nrightarrow$, or the empty heap.
  
  \item \texttt{Prop.t}: a proposition. It can be either an atomic one, the conjunction or disjunction between two proposition, or an existentially quantified proposition (i.e. $\exists x. prop$).
  
  \item \texttt{Cmd.t}: a command. It could be $skip$, a boolean assertion, an assignemnt to an arithmetic expression, a store, a load, an allocation, a deallocation, or \texttt{error}.
  
  \item \texttt{Prog.t} a program. It could be a command, the non-deterministic choice between two commands, the Kleene star, or the sequential composition of two or more programs. Note that a program in our syntax can either end with a semicolon or not.
\end{enumerate}
Finally, a well-formed input file has the shape \verb|{ P } C|, where \texttt{P} is a proposition (\texttt{Prop.t}) and \texttt{C} is a program (\texttt{Prog.t}).


The \texttt{main} function then applies a normalization step over the produced AST's representation of the precondition, followed by a simplification step.
Finally, the executor is invoked with the simplified precondition and the corresponding program.

During execution, the application continuously displays the current command being executed along with the executor’s state.

\subsection{ISL+ user's interaction}
When executing an \textit{Incorrectness Separation Logic+} triple, the front-end offers some degree of interaction depending on the rule being applied:

\begin{itemize}
  \item \texttt{Allocation:} three allocation strategies are available:
    \begin{itemize}
      \item Reuse the first available deallocated location, if any exists.
      \item Manually select which available deallocated location to reuse, if any exists
      \item Allocate a new memory location, ignoring any available deallocated ones.
    \end{itemize}
  \item \texttt{Choice:} the user can choose which branch to execute or execute both branches.
  \item \texttt{Iteration:} the user specifies the number $n$ of iterations to perform, and then decides whether to: 
    \begin{itemize}
      \item Collect all intermediate states produced during the rule's execution or only consider those after the $n$ iterations have been done.
      \item Only consider the states resulting after the $n$ iterations.
    \end{itemize}
\end{itemize}

This behavior is enabled with the \texttt{--step-exec} flag.

\section{Examples}

The following section will list some examples, starting from the input files content and showing the corresponding output.

The examples will highlight the verifier's key capabilities, progressing from simple to more complex scenarios.

Some of the examples include as last commented line a possible valid expected post condition.  

\subsection{SL+ Examples}

\begin{enumerate}

\item \textbf{Input file}: 
\begin{minted}{text}
{ y ↦ v }
x := [y]
# { x=v ∧ y ↦ v }
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
y ↦ v
=========================
Execution from state:
y¹ ↦ v¹ ∧ v = v¹ ∧ y = y¹ ∧ ⊤
-------------------------
v = v¹ ∧ x = v¹ ∧ y = y¹ ∧ y¹ ↦ v¹ ∧ x¹ = v¹
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ x ↦ _ }
[x] := y; 
# {x ↦ y }
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
x ↦ _
=========================
Execution from state:
x¹ ↦ _∧ x = x¹∧ ⊤
-------------------------
x = x¹ ∧ x¹ ↦ 0
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ emp }
x := alloc()
# { x ↦ _ } 
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
⊤
=========================
Execution from state:
⊤
-------------------------
x = x¹ ∧ x¹ ↦ _
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ x ↦ _ }
free(x); 
# {emp}
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
x ↦ _
=========================
Execution from state:
x¹ ↦ _ ∧ x = x¹ ∧ ⊤
-------------------------
x = x¹ ∧ x¹ ↦̸
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{false}
[x] := y   
#{false}
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
⊥
⊥ (all branches pruned)
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ (-(x × 5) + (8 / 4 - x) × -x / 7 + -x + -x × -1) = 0 }
skip
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
(-x + 2) × x / -7 - x × 5 = 0
=========================
Execution from state:
x = x¹ ∧ (-x¹ + 2) × x¹ / -7 - x¹ × 5 = 0
-------------------------
x = x¹ ∧ (-x¹ + 2) × x¹ / -7 - x¹ × 5 = 0
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ 0 <= x ∗ 0 <= y }
(y ← y + x)⋆
# y >= 0
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
0 ≤ y ∗ 0 ≤ x
=========================
Execution from state:
x = x¹ ∧ y = y¹ ∧ 0 ≤ y¹ ∧ 0 ≤ x¹
-------------------------
x = x¹ ∧ y = y¹ ∧ -y¹ ≤ 0 ∧ -x¹ ≤ 0
\end{minted}

\item \textbf{Input file}: 
\begin{minted}{text}
{ ⊤ }
(x = 1?; y ← x) + (x = 2?; y ← x)
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
⊤
=========================
Execution from state:
⊤
-------------------------
x = x¹ ∧ x¹ = 1
-------------------------
x = x² ∧ x² = 2
-------------------------
x = x¹ ∧ y = x¹ ∧ x¹ = 1 ∧ y¹ = 1
∨ x = x² ∧ y = x² ∧ x² = 2 ∧ y² = 2
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ ⊤ }

x := 0;
y := 1;
(y := y + 1)⋆;
(x := x - y)⋆;
((x > 0)?; z := 1) + ((x < 0)?; z := 2);
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
⊤
=========================
Execution from state:
⊤
-------------------------
x = x¹ ∧ x¹ = 0
-------------------------
x = x¹ ∧ y = y¹ ∧ x¹ = 0 ∧ y¹ = 1
-------------------------
x = x¹ ∧ y = y¹ ∧ -y¹ ≤ -1 ∧ x¹ = 0
-------------------------
x = x¹ ∧ y = y¹ ∧ -y¹ ≤ -1 ∧ x¹ ≤ 0
-------------------------
x = x¹ ∧ y = y¹ ∧ ⊥
-------------------------
<= 0 < 0 < 0 <= 0 x = x¹ ∧ y = y¹ ∧ -y¹ ≤ -1 ∧ x¹ < 0
-------------------------
x = x¹ ∧ y = y¹ ∧ z = z¹ ∧ -y¹ ≤ -1 ∧ x¹ < 0 ∧ z¹ = 2
\end{minted}

\end{enumerate}

\subsection{ISL+ Examples}

\begin{enumerate}
\item 
\textbf{Input file}: 
\begin{minted}{text}
{ x = nil }
[x] := y
# { er: x = nil }
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
x = nil
=========================
Execution from state:
nil = nil¹ ∧ x = x¹ ∧ x¹ = nil¹
-------------------------
[stuck]
nil = nil¹ ∧ x = x¹ ∧ x¹ = nil¹
-------------------------
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ x ↦̸ }
free(x)
# {er: x ↦̸ }
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
x ↦̸
=========================
Execution from state:
x¹ ↦̸ ∧ x = x¹ ∧ ⊤
-------------------------
[error]
x¹ ↦̸ ∧ x = x¹ ∧ 
-------------------------
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ x ↦ v }
free(x)
# {ok: x ↦̸ }
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
x ↦ v
=========================
Execution from state:
x¹ ↦ v¹ ∧ v = v¹ ∧ x = x¹ ∧ ⊤
-------------------------
v = v¹ ∧ x = x¹ ∧ x¹ ↦̸ ∧ ⊤
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ x = x' }
x := alloc()
# { ok: x ↦ _ }
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
x = x¹
=========================
Execution from state:
x = x² ∧ x² = x¹
-------------------------
x = x³ ∧ x³ ↦ _ ∧ ⊤ ∧ x² = x¹
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ y ↦̸ }
x := alloc()
# { ok: x ↦ v ∧ x = y }
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
y ↦̸
=========================
Execution from state:
y¹ ↦̸ ∧ y = y¹ ∧ ⊤
-------------------------
x = y¹ ∧ y = y¹ ∧ y¹ ↦ _ ∧ ⊤
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ x = nil }
free(x)
# {er: x = nil}
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ ⊤ }
x ← 0;
(x ← x + 1)⋆
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
⊤
=========================
Execution from state:
⊤
-------------------------
x = x¹ ∧ x¹ = 0
-------------------------
x = x⁸ ∧ emp ∧ ⊤ ∧ x¹ = 0 ∧ x² = 1 ∧ x³ = 2 ∧ x⁴ = 3 
∧ x⁵ = 4 ∧ x⁶ = 5 ∧ x⁷ = 6 ∧ x⁸ = 7
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
x = nil
=========================
Execution from state:
nil = nil¹ ∧ x = x¹ ∧ x¹ = nil¹
-------------------------
[stuck]
nil = nil¹ ∧ x = x¹ ∧ x¹ = nil¹
-------------------------
\end{minted}

\item 
\textbf{Input file}: 
\begin{minted}{text}
{ (-(x × 5) + (8 / 4 - x) × -x / 7 + -x + -x × -1) = 0 }
skip
\end{minted}

\textbf{Output}: 
\begin{minted}{text}
Simplified precondition:
(-x + 2) × x / -7 - x × 5 = 0
=========================
Execution from state:
x = x¹ ∧ (-x¹ + 2) × x¹ / -7 - x¹ × 5 = 0
-------------------------
x = x¹ ∧ emp ∧ ⊤ ∧ (-x¹ + 2) × x¹ / -7 - x¹ × 5 = 0
\end{minted}

\end{enumerate}

\end{document}
